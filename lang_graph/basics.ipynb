{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpg/ASoFdIFKiZN9Swv2p2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehan363/lang_chain/blob/main/basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***including necessary pakages***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HzcJHW6UkgLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -q langchain_google_genai langchain_core langchain_community tavily-python"
      ],
      "metadata": {
        "id": "ZiRXTg6w4vVm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***setting up chat model***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XB730QkCkuLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "2721-ffD4zMM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"hello?\")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1EXVdaf6Oku",
        "outputId": "9f1f9427-f45c-41e6-ad04-c1c4b775b9a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there! How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-4d96d63a-3f2e-4f40-a8f4-21bf4d8132b6-0', usage_metadata={'input_tokens': 3, 'output_tokens': 11, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "#create a message\n",
        "\n",
        "msg = HumanMessage(content=\"hello\", name=\"rehan\")\n",
        "\n",
        "#Creating list\n",
        "message = [msg]\n",
        "\n",
        "llm.invoke(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezBGipsM8uQ4",
        "outputId": "57627acc-045b-4246-b68d-4529d1f242be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there! How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-54244656-bbcd-4878-a92f-18d90f73226a-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***another way***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xki3JYilBvh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "#create a message\n",
        "\n",
        "#Creating list\n",
        "message = [ HumanMessage(content=\"hello\", name=\"rehan\"),\n",
        "          AIMessage(content='Hello there! How can I help you today?', name=\"AI Assistance\")\n",
        "\n",
        "]\n",
        "\n",
        "llm.invoke(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIZ6OCeRBuPC",
        "outputId": "1ef8c006-f4ca-42d6-a013-349c9c4ea9e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-09f63558-3d2b-4f72-9ce5-64774324c8e4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 0, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding search functionality in langchain by adding TAVILY_API_KEY**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KXozlJFYqjY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the API key from userdata\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# Set the environment variable correctly\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Initialize TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=2)\n",
        "\n",
        "# Perform the search\n",
        "search_docs = tavily_search.invoke(\"what is langgraph\")"
      ],
      "metadata": {
        "id": "-uUwLaB_vg6E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_docs"
      ],
      "metadata": {
        "id": "dxg7JjSbv_kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4318e7-6ca6-445d-ae75-dc4c0a5728cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787',\n",
              "  'content': \"LangGraph is a low-level framework that offers extensive customisation options, allowing you to build precisely what you need. Since LangGraph is built on top of LangChain, it's seamlessly integrated into its ecosystem, making it easy to leverage existing tools and components. However, there are areas where LangGrpah could be improved:\"},\n",
              " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents in a structured and efficient manner. Learn how to install, use, and customize LangGraph to build complex, scalable, and flexible multi-agent systems.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}
